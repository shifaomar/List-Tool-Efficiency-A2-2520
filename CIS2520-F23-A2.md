# CIS 2520 F23 Assignment 2: List tool efficiency

This assignment will let us see how these efficiency discussions we
have been having in the course actually play out in the real world.

We are going to build several different programs that handle the same
task with different data structures and directly time how long it takes
to do the work under different scenarios.

## Timing program operations

Timing program operations is not an exact science, as on any multi-user
operating system, many things may be going on at the same time.
We therefore not only want to see how much time has elapsed between
starting and ending our task, but we want to calculate an average over
multiple runs of the same task so that we can have some understanding
of variability.

Even this doesn't tell us the whole story, as the elapsed time combines
system time (time used within operating system calls) with "user time"
(time actually running our "user code").  Sometimes we talk about
"door-to-door time" meaning the actual total time elapsed.

There are tools that can give you this breakdown of how long a given
running program took to do its work, notably `time(1)`, however this
is hard to integrate into our programs to let them time themselves.

We will therefore content ourselves with using the `clock(3)` function.
Calling `clock(3)` before and after our work and taking the difference
will give us the number of "clock ticks" that occurred during out work.
There are `CLOCKS_PER_SECOND` clock ticks every second.  This lets us
time events that are less than 1s long.

## Programs desired

We will have four programs.  Each of them will be able to read and
process FASTA data, which is genomics data as used in the
[Uniprot](https://www.uniprot.org/) protein analysis project.

This project has been chosen because it represents a type of very active
scientific research that only needs files of moderate size.  The file
record that Uniprot uses is called FASTA, and this is a popular format
in genomics research.  Code has been provided for you to parse the
data from the file into a record, `FASTArecord`.

We will have four programs that work with this data:

* `llloadonly` -- loads the data from the file, but does not store it.
		This one is provided for you.  Use its design as a pattern to
		get you started on the other files.
* `arraydouble` -- loads the data and stores all the records into an
		array.  As we don't know how big the array must be in advance,
		we will have to grow the array as we go and copy the data.
* `llheadonly` -- loads the data into a simple linked list.  Appending
		the data to this list requires us to chase through the list.
* `llheadtail` -- loads the data into a linked list for which we are
		managing both a pointer to the head and tail of the list, as
		we discussed in the notes.


## Program operation

Each of our programs will work the same way.  Running the program
with a '`-R <REPEATS>`' flag will repeat the program run the indicated
number of times and report the average of the times for each run.

For example, the following command line will run the "head and tail" version
of the linked list code five times and report on the results:

```
$ ./llheadtail -R 5 /home/courses/cis2520/data/uniprot_sprot-100000.fasta
........... 100000 FASTA records
........... 100000 FASTA records
........... 100000 FASTA records
........... 100000 FASTA records
........... 100000 FASTA records
1.874 seconds taken for processing total
On average: 0 minutes, 0.375 second per run
```

### Operation of `arraydouble` program

When growing arrays, to avoid allocating all the time, a common strategy
is to simply double the amount of allocation so far at any point that
you discover that the array is not big enough.

This wastes space, of course, as there will be potentially many records
allocated but unused at the end of your array.  We want to be able to
track this, so be sure to print out how much of your allocation is unused
"wasted space" after each run.  Sample output might be:

```
$ ./arraydouble -R 5 /home/courses/cis2520/data/uniprot_sprot-100000.fasta 
........... 100000 FASTA records -- 131072 allocated (23.706% waste)
........... 100000 FASTA records -- 131072 allocated (23.706% waste)
........... 100000 FASTA records -- 131072 allocated (23.706% waste)
........... 100000 FASTA records -- 131072 allocated (23.706% waste)
........... 100000 FASTA records -- 131072 allocated (23.706% waste)
1.743 seconds taken for processing total
On average: 0 minutes, 0.349 second per run
```

Note that both the timings, allocation amounts and waste factors are
not expected to be exactly the same between students, and between your
solution and the example above.

## Program data

The full database of Uniprot FASTA records has been downloaded for you
and stored in the course directory at

```
/home/courses/cis2520/data/uniprot_sprot*.fasta
```

***DO NOT COPY THESE FILE INTO YOUR HOME DIRECTORY***.
There is no need to do this, as this will simply waste lots of space
on the disk.  You can simply read the files
**directly from the course directory** and save both computing space
and time.

This file contains 570,157 records in FASTA format forming the database
of proteins that Uniprot has worked with so far.

Dealing with files with many records in them makes it very difficult
to debug problems, so I have truncated the file into smaller versions
that you may find useful for your initial testing.  The full set of
files are these:

* `/home/courses/cis2520/data/uniprot_sprot.fasta` -- full data set of 570,157 records
* `/home/courses/cis2520/data/uniprot_sprot-100000.fasta` -- truncated data set of only one hundred thousand records
* `/home/courses/cis2520/data/uniprot_sprot-20000.fasta` -- smaller truncated data set of only twenty thousand records

Again, there is ***NO NEED AT ALL*** to copy these files to your
own working directories, and you ***ABSOLUTELY*** should not add
them to your `github` repositories.  Doing so will make working on
this assignment ***painfully slow*** for **you**, so it is not in
your interest to do this.

# Code provided

Again, I have provided you a good starting point with some code for you
to use.  Use these files to get started, however you can adapt these
and are encouraged to add more files for your own design.  In particular,
you will need to think about how you will manage both the "head" **and**
the "tail" nicely for the adapted linked list in the "llheadtail" utility.

C code files:

* `fasta.h` and `fasta_read.c` -- these provide you a tool to read FASTA
	format records into a structure in memory.  You should not need to
	modify these files.
* `LLvNode.h` and `LLvNode.c` -- these are marginally modified versions of
	the code provided for the linked list in A1.  The only difference is
	that instead of providing an integer as a data value, a `void *` is
	provided.  Use the `void *` to point at a FASTA record in order to
	store the record using the list.
* `llloadonly_main.c` -- a complete implementation of a program to load
	the records and compute the relevant timing.  Note however that this
	program does not actually **store** the records anywhere.  Creating
	programs that do that will be your job.
* `arraydouble_main.c`, `llheadonly_main.c` and `llheadtail_main.c` -- these
	stub programs give you a place to start with your own implementations.

Additional files:

* `makefile` -- you will need to update this file with any new `.c` files
	that you write as part of this project, but it is relatively complete.
	* Note that your could absolutely should compile cleanly 
	on `linux.socs` (with no errors or warnings shown) using 
	the `-Wall` flag as set in the `CFLAGS` variable.

* `runFullExperiment` -- a convenience script to run all of the programs
	on `linux.socs` using the data files in the course directory as
	input.

* `valgrind-memcheck` -- a tool that runs `valgrind` in "`memcheck`" mode
	with the additional `--leak-check=full` flag.  Give the entire
	command line, including the program you are trying to debug,
	as arguments to this script, *e.g.;*:

```
./valgrind-memcheck arraydouble /home/courses/cis2520/data/uniprot_sprot-20000.fasta 
```

## Required output

Your output should conform to the sample above.

* Floating point numbers should be printed with three decimal places of
accuracy.
* The array based tool (and only the array based tool) should report waste



# Focus of the grading

Important factors in the grading include (in decreasing order of importance):

* **building correctly** using `make(1)`
	* Code that does not build using `make(1)` **on the linux.socs machines** will get no marks for functionality
		* Be sure to **test your code thoroughly** 
		* Running `make clean` followed by `make` will ensure a complete rebuild
* running correctly in all four cases
* **integrating** your solution into the provided code
* having **no memory errors or leaks** when run using `valgrind(1)`
* providing **documentation** through a "`README.txt`" (or "`README.md`") file containing the following information:
	* Your name and student number
	* Any resource you used for assistance
	* The state of your implementation -- whether any functionality is missing or the assignment is complete
	* A short summary of what you have learned about the relative amounts
		of time required to perform these tasks

